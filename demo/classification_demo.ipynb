{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 Demo: Random-Forest Based Activity Classification\n",
    "\n",
    "*Disclaimer:  This sample code and the reported results are represent the processed reported in the Pilot Study.  When running these processing with ML models incorporating stochasticity, the results shown in this demonstration notebook may differ slightly from those in the Pilot Study.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import shap\n",
    "import boruta\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from string type task ID to integer task ID\n",
    "task_label_map = {'Angry': 0, 'Chewing': 1, 'Eye': 2, 'Eye-Iso': 3, 'In-Iso': 4, 'Jaw': 5, 'L Gaze-L': 6, \\\n",
    "                  'L Gaze-R': 7, 'Out-Iso': 8, 'Sad': 9, 'Smile-Iso': 10, 'Surprise': 11, 'Swallowing': 12, \\\n",
    "                  'Talk': 13, 'Up Gaze': 14, 'Wrinkle-Iso': 15}\n",
    "\n",
    "reverse_task_label_map = {value: key for key, value in task_label_map.items()}\n",
    "\n",
    "subject_ids = ['subject0', 'subject1', 'subject2', 'subject3', 'subject4', \\\n",
    "               'subject5', 'subject6', 'subject7', 'subject8', 'subject9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 37.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of features and labels.  Each dictionary maps a subject's\n",
    "# ID to a set of activity features or activity labels, respectively.\n",
    "features = {sid: [] for sid in subject_ids}\n",
    "labels = {sid: [] for sid in subject_ids}\n",
    "\n",
    "# Read feature data from csv files\n",
    "feature_data_dir = '../data/feature_data'\n",
    "for sid in tqdm(subject_ids):\n",
    "    for time in ['Morning', 'Evening']:\n",
    "        df = pd.read_csv(os.path.join(feature_data_dir, sid, '{}_{}_variables.csv'.format(sid, time)))\n",
    "        df['Task Label'] = df['Task Label'].apply(lambda x: task_label_map[x])\n",
    "        \n",
    "        # Remove Event Duration feature, as this feature is only applicable to\n",
    "        # tasks performed for specified durations.\n",
    "        df.drop(['Event Duration (s)'], axis=1, inplace=True)\n",
    "        \n",
    "        y = np.array(df['Task Label'])\n",
    "        \n",
    "        df.drop(['Task Label'], axis=1, inplace=True)\n",
    "        X = df.to_numpy()\n",
    "        \n",
    "        features[sid].append(X)\n",
    "        labels[sid].append(y)\n",
    "        \n",
    "    features[sid] = np.vstack(features[sid])\n",
    "    labels[sid] = np.hstack(labels[sid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([features[sid] for sid in subject_ids])\n",
    "y = np.hstack([labels[sid] for sid in subject_ids])\n",
    "\n",
    "shuffled_inds = np.random.permutation(X.shape[0])\n",
    "X = X[shuffled_inds]\n",
    "y = y[shuffled_inds]\n",
    "\n",
    "# Perform a stratified split of the pooled set of actions \n",
    "# (from all subjects) into training and test sets\n",
    "test_size = 0.2\n",
    "test_inds = []\n",
    "train_inds = []\n",
    "for class_id in list(task_label_map.values()):\n",
    "    class_sample_idxs = np.where(y==class_id)[0]\n",
    "    class_sample_count = len(class_sample_idxs)\n",
    "    class_sample_idxs = np.random.permutation(class_sample_idxs)\n",
    "    test_inds.append(class_sample_idxs[:int(test_size*class_sample_count)])\n",
    "    train_inds.append(class_sample_idxs[int(test_size*class_sample_count):])\n",
    "train_inds = np.hstack(train_inds)\n",
    "test_inds = np.hstack(test_inds)\n",
    "\n",
    "X_train, X_test = X[train_inds], X[test_inds]\n",
    "y_train, y_test = y[train_inds], y[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Classification Report Summary:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.27      0.30        15\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       0.89      1.00      0.94        16\n",
      "           3       0.53      0.56      0.55        16\n",
      "           4       0.50      0.44      0.47        16\n",
      "           5       0.84      1.00      0.91        16\n",
      "           6       0.79      0.79      0.79        14\n",
      "           7       0.86      0.86      0.86        14\n",
      "           8       0.43      0.38      0.40        16\n",
      "           9       0.43      0.56      0.49        16\n",
      "          10       0.72      0.81      0.76        16\n",
      "          11       0.78      0.44      0.56        16\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       0.94      1.00      0.97        15\n",
      "          14       0.92      0.80      0.86        15\n",
      "          15       0.35      0.38      0.36        16\n",
      "\n",
      "    accuracy                           0.70       249\n",
      "   macro avg       0.70      0.70      0.70       249\n",
      "weighted avg       0.70      0.70      0.70       249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feature_means = np.mean(X_train, axis=0)\n",
    "train_feature_stds = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train-train_feature_means)/train_feature_stds\n",
    "X_test = (X_test-train_feature_means)/train_feature_stds\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "\n",
    "print('Test Set Classification Report Summary:')\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
