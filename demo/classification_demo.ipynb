{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 Demo: Random-Forest Based Activity Classification\n",
    "\n",
    "*Disclaimer:  This sample code and the reported results are represent the processed reported in the Pilot Study.  When running these processing with ML models incorporating stochasticity, the results shown in this demonstration notebook may differ slightly from those in the Pilot Study.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import shap\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from string type task ID to integer task ID\n",
    "task_label_map = {'Angry': 0, 'Chewing': 1, 'Eye': 2, 'Eye-Iso': 3, 'In-Iso': 4, 'Jaw': 5, 'L Gaze-L': 6, \\\n",
    "                  'L Gaze-R': 7, 'Out-Iso': 8, 'Sad': 9, 'Smile-Iso': 10, 'Surprise': 11, 'Swallowing': 12, \\\n",
    "                  'Talk': 13, 'Up Gaze': 14, 'Wrinkle-Iso': 15}\n",
    "\n",
    "reverse_task_label_map = {value: key for key, value in task_label_map.items()}\n",
    "\n",
    "subject_ids = ['subject0', 'subject1', 'subject2', 'subject3', 'subject4', \\\n",
    "               'subject5', 'subject6', 'subject7', 'subject8', 'subject9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 50.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of features and labels.  Each dictionary maps a subject's\n",
    "# ID to a set of activity features or activity labels, respectively.\n",
    "features = {sid: [] for sid in subject_ids}\n",
    "labels = {sid: [] for sid in subject_ids}\n",
    "\n",
    "# Read feature data from csv files\n",
    "feature_data_dir = '../data/feature_data'\n",
    "for sid in tqdm(subject_ids):\n",
    "    for time in ['Morning', 'Evening']:\n",
    "        df = pd.read_csv(os.path.join(feature_data_dir, sid, '{}_{}_variables.csv'.format(sid, time)))\n",
    "        df['Task Label'] = df['Task Label'].apply(lambda x: task_label_map[x])\n",
    "        \n",
    "        # Remove Event Duration feature, as this feature is only applicable to\n",
    "        # tasks performed for specified durations.\n",
    "        df.drop(['Event Duration (s)'], axis=1, inplace=True)\n",
    "        \n",
    "        y = np.array(df['Task Label'])\n",
    "        \n",
    "        df.drop(['Task Label'], axis=1, inplace=True)\n",
    "        X = df.to_numpy()\n",
    "        \n",
    "        features[sid].append(X)\n",
    "        labels[sid].append(y)\n",
    "        \n",
    "    features[sid] = np.vstack(features[sid])\n",
    "    labels[sid] = np.hstack(labels[sid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_feature_inds = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, \\\n",
    "                            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])\n",
    "\n",
    "v2_feature_inds = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, \\\n",
    "                            14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, \\\n",
    "                            26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, \\\n",
    "                            38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, \\\n",
    "                            50, 51, 52, 53, 54, 55, 56, 157, 158, 159, 160])\n",
    "\n",
    "v3_feature_inds = np.arange(161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([features[sid] for sid in subject_ids])\n",
    "y = np.hstack([labels[sid] for sid in subject_ids])\n",
    "\n",
    "shuffled_inds = np.random.permutation(X.shape[0])\n",
    "X = X[shuffled_inds]\n",
    "y = y[shuffled_inds]\n",
    "\n",
    "# Perform a stratified split of the pooled set of actions \n",
    "# (from all subjects) into training and test sets\n",
    "test_size = 0.2\n",
    "test_inds = []\n",
    "train_inds = []\n",
    "for class_id in list(task_label_map.values()):\n",
    "    class_sample_idxs = np.where(y==class_id)[0]\n",
    "    class_sample_count = len(class_sample_idxs)\n",
    "    class_sample_idxs = np.random.permutation(class_sample_idxs)\n",
    "    test_inds.append(class_sample_idxs[:int(test_size*class_sample_count)])\n",
    "    train_inds.append(class_sample_idxs[int(test_size*class_sample_count):])\n",
    "train_inds = np.hstack(train_inds)\n",
    "test_inds = np.hstack(test_inds)\n",
    "\n",
    "X_train_v1, X_test_v1 = X[train_inds][:,v1_feature_inds], X[test_inds][:,v1_feature_inds]\n",
    "X_train_v2, X_test_v2 = X[train_inds][:,v2_feature_inds], X[test_inds][:,v2_feature_inds]\n",
    "X_train_v3, X_test_v3 = X[train_inds][:,v3_feature_inds], X[test_inds][:,v3_feature_inds]\n",
    "y_train, y_test = y[train_inds], y[test_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Classification Report Summary:\n",
      "\n",
      "Classification Performance (feature set version 0):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.27      0.33        15\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       0.80      1.00      0.89        16\n",
      "           3       0.43      0.19      0.26        16\n",
      "           4       0.36      0.62      0.45        16\n",
      "           5       0.94      1.00      0.97        16\n",
      "           6       0.36      0.29      0.32        14\n",
      "           7       0.46      0.43      0.44        14\n",
      "           8       0.64      0.44      0.52        16\n",
      "           9       0.28      0.31      0.29        16\n",
      "          10       0.58      0.94      0.71        16\n",
      "          11       0.60      0.38      0.46        16\n",
      "          12       1.00      0.88      0.93        16\n",
      "          13       0.88      1.00      0.94        15\n",
      "          14       0.67      0.80      0.73        15\n",
      "          15       0.15      0.12      0.14        16\n",
      "\n",
      "    accuracy                           0.61       249\n",
      "   macro avg       0.60      0.60      0.59       249\n",
      "weighted avg       0.60      0.61      0.59       249\n",
      "\n",
      "\n",
      "Classification Performance (feature set version 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.40      0.43        15\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       0.89      1.00      0.94        16\n",
      "           3       0.62      0.31      0.42        16\n",
      "           4       0.41      0.75      0.53        16\n",
      "           5       0.94      0.94      0.94        16\n",
      "           6       0.75      0.64      0.69        14\n",
      "           7       0.71      0.71      0.71        14\n",
      "           8       0.58      0.44      0.50        16\n",
      "           9       0.35      0.38      0.36        16\n",
      "          10       0.57      0.81      0.67        16\n",
      "          11       0.62      0.50      0.55        16\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      1.00      1.00        15\n",
      "          14       0.69      0.73      0.71        15\n",
      "          15       0.50      0.31      0.38        16\n",
      "\n",
      "    accuracy                           0.68       249\n",
      "   macro avg       0.69      0.68      0.68       249\n",
      "weighted avg       0.69      0.68      0.67       249\n",
      "\n",
      "\n",
      "Classification Performance (feature set version 2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.53      0.48        15\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       0.80      1.00      0.89        16\n",
      "           3       0.75      0.38      0.50        16\n",
      "           4       0.56      0.62      0.59        16\n",
      "           5       1.00      1.00      1.00        16\n",
      "           6       0.71      0.71      0.71        14\n",
      "           7       0.83      0.71      0.77        14\n",
      "           8       0.50      0.25      0.33        16\n",
      "           9       0.33      0.38      0.35        16\n",
      "          10       0.58      0.94      0.71        16\n",
      "          11       0.36      0.31      0.33        16\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      1.00      1.00        15\n",
      "          14       0.73      0.73      0.73        15\n",
      "          15       0.50      0.44      0.47        16\n",
      "\n",
      "    accuracy                           0.69       249\n",
      "   macro avg       0.69      0.69      0.68       249\n",
      "weighted avg       0.69      0.69      0.68       249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test Set Classification Report Summary:')\n",
    "\n",
    "training_data_versions = [X_train_v1, X_train_v2, X_train_v3]\n",
    "testing_data_versions = [X_test_v1, X_test_v2, X_test_v3]\n",
    "\n",
    "for i, [X_train, X_test] in enumerate(zip(training_data_versions, testing_data_versions)):\n",
    "    train_feature_means = np.mean(X_train, axis=0)\n",
    "    train_feature_stds = np.std(X_train, axis=0)\n",
    "\n",
    "    X_train = (X_train-train_feature_means)/train_feature_stds\n",
    "    X_test = (X_test-train_feature_means)/train_feature_stds\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = clf.predict(X_test)\n",
    "\n",
    "    print('\\nClassification Performance (feature set version {}):'.format(i))\n",
    "    print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Feature Selection With Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Features (102 total):\n",
      "['Perceptible Onset Time (s)'\n",
      " 'EMG Mean Absolute Amplitude - Channel 1 (uV)'\n",
      " 'EMG Mean Absolute Amplitude - Channel 2(uV)'\n",
      " 'EMG Max Absolute Amplitude - Channel 1 (uV)'\n",
      " 'EMG Max Absolute Amplitude - Channel 2 (uV)'\n",
      " 'EMG Peak Frequency Contractions - Channel 1'\n",
      " 'EMG Peak Frequency Contractions - Channel 2'\n",
      " 'EMG 10-33Hz Bandpower - Channel 1 (dB)'\n",
      " 'EMG 33-56Hz Bandpower - Channel 1 (dB)'\n",
      " 'EMG 56-79Hz Bandpower - Channel 1 (dB)'\n",
      " 'EMG 79-102Hz Bandpower - Channel 1 (dB)'\n",
      " 'EMG 102-125Hz Bandpower - Channel 1 (dB)'\n",
      " 'EMG 10-33Hz Bandpower - Channel 2 (dB)'\n",
      " 'EMG 33-56Hz Bandpower - Channel 2 (dB)'\n",
      " 'EMG 56-79Hz Bandpower - Channel 2 (dB)'\n",
      " 'EMG 79-102Hz Bandpower - Channel 2 (dB)'\n",
      " 'EMG 102-125Hz Bandpower - Channel 2 (dB)'\n",
      " 'EMG Amplitude Skew - Channel 1' 'EMG Amplitude Skew - Channel 2'\n",
      " 'EMG Amplitude Kurtosis - Channel 1' 'EMG Amplitude Kurtosis - Channel 2'\n",
      " 'EMG Variance - Channel 1' 'EMG Variance - Channel 2'\n",
      " 'EMG 25th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EMG 50th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EMG 75th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EMG 90th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EMG 25th Percentile Absolute Amplitude - Channel 2'\n",
      " 'EMG 50th Percentile Absolute Amplitude - Channel 2'\n",
      " 'EMG 75th Percentile Absolute Amplitude - Channel 2'\n",
      " 'EMG 90th Percentile Absolute Amplitude - Channel 2'\n",
      " 'EMG Zero Crossing Rate - Channel 1' 'EMG Zero Crossing Rate - Channel 2'\n",
      " 'EMG Standard Deviation - Channel 1' 'EMG Standard Deviation - Channel 2'\n",
      " 'EMG Abolute Amplitude Standard Deviation - Channel 1'\n",
      " 'EMG Abolute Amplitude Standard Deviation - Channel 2'\n",
      " 'EMG Root Mean Square - Channel 1' 'EMG Root Mean Square - Channel 2'\n",
      " 'EMG Detrended Fluctuation Hurst Parameter - Channel 1'\n",
      " 'EMG Detrended Fluctuation Hurst Parameter - Channel 2'\n",
      " 'EMG Petrosian Fractal Dimension - Channel 1'\n",
      " 'EMG Petrosian Fractal Dimension - Channel 2'\n",
      " 'EMG Approximate Entropy - Channel 1'\n",
      " 'EMG Approximate Entropy - Channel 2' 'EMG Spectral Entropy - Channel 1'\n",
      " 'EMG Spectral Entropy - Channel 2'\n",
      " 'EEG Mean Absolute Amplitude - Channel 1 (uV)'\n",
      " 'EEG Max Absolute Amplitude - Channel 1 (uV)'\n",
      " 'EEG 1-4Hz Bandpower - Channel 1 (dB)'\n",
      " 'EEG 4-7Hz Bandpower - Channel 1 (dB)'\n",
      " 'EEG 7-12Hz Bandpower - Channel 1 (dB)'\n",
      " 'EEG 12-302Hz Bandpower - Channel 1 (dB)'\n",
      " 'EEG 12-302Hz Bandpower - Channel 2 (dB)'\n",
      " 'EEG Amplitude Kurtosis - Channel 1' 'EEG Amplitude Kurtosis - Channel 2'\n",
      " 'EEG Variance - Channel 1'\n",
      " 'EEG 25th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EEG 50th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EEG 75th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EEG 90th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EEG 25th Percentile Absolute Amplitude - Channel 2'\n",
      " 'EEG 50th Percentile Absolute Amplitude - Channel 2'\n",
      " 'EEG Zero Crossing Rate - Channel 2' 'EEG Standard Deviation - Channel 1'\n",
      " 'EEG Abolute Amplitude Standard Deviation - Channel 1'\n",
      " 'EEG Root Mean Square - Channel 1'\n",
      " 'EEG Detrended Fluctuation Hurst Parameter - Channel 1'\n",
      " 'EEG Detrended Fluctuation Hurst Parameter - Channel 2'\n",
      " 'EEG Petrosian Fractal Dimension - Channel 1'\n",
      " 'EEG Petrosian Fractal Dimension - Channel 2'\n",
      " 'EEG Approximate Entropy - Channel 1' 'EEG Spectral Entropy - Channel 1'\n",
      " 'EOG Mean Absolute Amplitude - Channel 1 (uV)'\n",
      " 'EOG Max Absolute Amplitude - Channel 1 (uV)'\n",
      " 'EOG 0.5-4Hz Bandpower - Channel 1 (dB)'\n",
      " 'EOG 4-10Hz Bandpower - Channel 1 (dB)' 'EOG Amplitude Skew - Channel 1'\n",
      " 'EOG Amplitude Skew - Channel 2' 'EOG Amplitude Kurtosis - Channel 1'\n",
      " 'EOG Amplitude Kurtosis - Channel 2' 'EOG Variance - Channel 1'\n",
      " 'EOG 25th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EOG 50th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EOG 75th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EOG 90th Percentile Absolute Amplitude - Channel 1'\n",
      " 'EOG Zero Crossing Rate - Channel 1' 'EOG Zero Crossing Rate - Channel 2'\n",
      " 'EOG Standard Deviation - Channel 1'\n",
      " 'EOG Abolute Amplitude Standard Deviation - Channel 1'\n",
      " 'EOG Root Mean Square - Channel 1'\n",
      " 'EOG Detrended Fluctuation Hurst Parameter - Channel 1'\n",
      " 'EOG Detrended Fluctuation Hurst Parameter - Channel 2'\n",
      " 'EOG Petrosian Fractal Dimension - Channel 1'\n",
      " 'EOG Petrosian Fractal Dimension - Channel 2'\n",
      " 'EOG Approximate Entropy - Channel 1'\n",
      " 'EOG Approximate Entropy - Channel 2' 'EOG Spectral Entropy - Channel 1'\n",
      " 'EOG Spectral Entropy - Channel 2'\n",
      " 'EOG Initial Deflection (Clipped) - Channel 1'\n",
      " 'EOG Initial Deflection (Clipped) - Channel 2'\n",
      " 'EOG Deflection Sign - Channel 1']\n",
      "\n",
      "Weakly Supported Features (5 total):\n",
      "['EMG Peak Frequency 1 - Channel 1 (Hz)' 'EEG Amplitude Skew - Channel 2'\n",
      " 'EEG Zero Crossing Rate - Channel 1' 'EEG Spectral Entropy - Channel 2'\n",
      " 'EOG 25th Percentile Absolute Amplitude - Channel 2']\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "X_train, X_test = X[train_inds], X[test_inds]\n",
    "train_feature_means = np.mean(X_train, axis=0)\n",
    "train_feature_stds = np.std(X_train, axis=0)\n",
    "X_train = (X_train-train_feature_means)/train_feature_stds\n",
    "X_test = (X_test-train_feature_means)/train_feature_stds\n",
    "\n",
    "clf_reduced = RandomForestClassifier(n_estimators=500)\n",
    "feat_selector = BorutaPy(estimator=clf_reduced, n_estimators='auto', max_iter=100)\n",
    "feat_selector.fit(X_train, y_train)\n",
    "\n",
    "supported_features = np.array(df.columns)[feat_selector.support_]\n",
    "print('Supported Features ({} total):'.format(len(supported_features)))\n",
    "print(supported_features)\n",
    "      \n",
    "weak_support_features = np.array(df.columns)[feat_selector.support_weak_]\n",
    "print('\\nWeakly Supported Features ({} total):'.format(len(weak_support_features)))\n",
    "print(weak_support_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Performance (Boruta feature set)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.27      0.31        15\n",
      "           1       0.94      1.00      0.97        16\n",
      "           2       1.00      0.88      0.93        16\n",
      "           3       0.55      0.38      0.44        16\n",
      "           4       0.44      0.50      0.47        16\n",
      "           5       0.84      1.00      0.91        16\n",
      "           6       0.75      0.64      0.69        14\n",
      "           7       0.71      0.71      0.71        14\n",
      "           8       0.58      0.44      0.50        16\n",
      "           9       0.38      0.50      0.43        16\n",
      "          10       0.52      0.81      0.63        16\n",
      "          11       0.75      0.38      0.50        16\n",
      "          12       0.89      1.00      0.94        16\n",
      "          13       1.00      0.93      0.97        15\n",
      "          14       0.62      0.67      0.65        15\n",
      "          15       0.42      0.50      0.46        16\n",
      "\n",
      "    accuracy                           0.66       249\n",
      "   macro avg       0.67      0.66      0.66       249\n",
      "weighted avg       0.67      0.66      0.66       249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boruta_feature_inds = np.where(feat_selector.support_)[0]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(X_train[:,boruta_feature_inds], y_train)\n",
    "y_hat = clf.predict(X_test[:,boruta_feature_inds])\n",
    "\n",
    "print('\\nClassification Performance (Boruta feature set)')\n",
    "print(classification_report(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
